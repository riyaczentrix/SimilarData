import pandas as pd
import nltk
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np # Import numpy for matrix operations

# --- NLTK Data Download (Run these lines once if you haven't downloaded them) ---
# These try-except blocks ensure that NLTK resources are downloaded only if they
# are not already present, preventing repeated downloads.
nltk.download('stopwords', quiet=True)
nltk.download('punkt', quiet=True)
nltk.download('wordnet', quiet=True) # Added wordnet as it's a common dependency

# --- Configuration ---
FILE_NAME = 'FullFinalData.csv' # Make sure this CSV file is in the same directory as your script
MAIL_BODY_COLUMN = 'DecodedBody' # CORRECTED: Using the provided column name 'DecodedBody'
OUTPUT_CSV_WITH_SIMILARITY = 'FullFinalData_with_most_similar_matches.csv' # Output file name for the full DataFrame

# --- Text Preprocessing Function (for similarity calculation) ---
def preprocess_text(text):
    """
    Cleans and preprocesses text data by extracting only the first line
    (content before the first newline character) and then applying cleaning steps.
    This processed text is used for similarity calculations.
    1. Handling NaN values.
    2. Converting text to string.
    3. Explicitly handles cases where text becomes 'nan' or effectively empty after conversion.
    4. Extracts only the content before the first newline character.
    5. Removes non-alphabetic characters (keeping only letters and spaces).
    6. Normalizes multiple spaces to single spaces.
    7. Strips leading/trailing spaces.
    8. Converts the entire text to lowercase.
    """
    if pd.isna(text):
        return ""
    text = str(text)

    # If text is literally "nan" (from NaN conversion) or just whitespace, return empty string
    if text.strip().lower() == 'nan' or not text.strip():
        return ""

    # Find the first newline character and take only the text before it
    first_newline_index = text.find('\n')
    if first_newline_index != -1:
        first_line_segment = text[:first_newline_index]
    else:
        # If no newline is found, consider the entire text as the first line
        first_line_segment = text

    # Apply cleaning steps to the extracted first line segment
    # Remove non-alphabetic characters (keeping only letters and spaces)
    cleaned_text = re.sub(r'[^a-zA-Z\s]', '', first_line_segment)
    
    # Normalize multiple spaces to single spaces, strip leading/trailing spaces, and lowercase
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip().lower()
    
    return cleaned_text

# --- Helper Function (for displaying original first line) ---
def get_first_line_raw(text):
    """
    Extracts only the first line of text, preserving original casing and punctuation.
    1. Handles NaN values.
    2. Converts text to string.
    3. Explicitly handles cases where text becomes 'nan' or effectively empty after conversion.
    4. Extracts only the content before the first newline character.
    5. Strips leading/trailing whitespace.
    """
    if pd.isna(text):
        return ""
    text = str(text)

    # If text is literally "nan" (from NaN conversion) or just whitespace, return empty string
    if text.strip().lower() == 'nan' or not text.strip():
        return ""

    # Find the first newline character and take only the text before it
    first_newline_index = text.find('\n')
    if first_newline_index != -1:
        first_line_segment = text[:first_newline_index]
    else:
        # If no newline is found, consider the entire text as the first line
        first_line_segment = text
    
    # Just strip leading/trailing whitespace, no other cleaning
    return first_line_segment.strip()


# --- Load the dataset from CSV ---
try:
    # Assuming the CSV has a header row, so header=None is removed
    df = pd.read_csv(FILE_NAME, encoding='mac_roman')
    print(f"Successfully loaded '{FILE_NAME}'.")
except FileNotFoundError:
    print(f"Error: '{FILE_NAME}' not found. Please ensure the file is in the same directory as the script.")
    exit() # Exit the script if the file is not found
except UnicodeDecodeError as e:
    print(f"Error: Could not decode the file with 'mac_roman' encoding. Please check the file encoding or try another one. Details: {e}")
    print("Common encodings to try: 'utf-8', 'latin1', 'cp1252'")
    exit()
except Exception as e:
    print(f"An error occurred while loading the CSV file: {e}")
    exit()

# --- Debugging: Print head of raw DataFrame after loading ---
print("\n--- Head of RAW DataFrame after loading CSV ---")
print(df.head())
print(f"Total rows in raw DataFrame: {len(df)}")


# Ensure the MAIL_BODY_COLUMN exists in the DataFrame
if MAIL_BODY_COLUMN not in df.columns:
    print(f"Error: Column '{MAIL_BODY_COLUMN}' not found in '{FILE_NAME}'. Please check the column name.")
    print(f"Available columns are: {df.columns.tolist()}")
    exit()

# --- Debugging: Print a few raw mail body entries ---
print(f"\n--- First 5 non-NaN entries from '{MAIL_BODY_COLUMN}' (raw) ---")
# Use .head(5) on the Series to get the first few entries, then convert to list
print(df[MAIL_BODY_COLUMN].dropna().head().tolist())


# --- Preprocess mail bodies and prepare for comparison ---
print(f"\nPreprocessing '{MAIL_BODY_COLUMN}' for all rows...")
df['processed_mail_body'] = df[MAIL_BODY_COLUMN].apply(preprocess_text)

# Create a DataFrame containing only valid (non-empty processed) mail bodies for vectorization
# This also preserves the original index for mapping back to df
df_comparable = df[df['processed_mail_body'] != ''].copy()

if df_comparable.empty:
    print("\nNo valid mail bodies found after preprocessing and filtering. Cannot perform similarity comparisons.")
    print("Please check your CSV file's 'DecodedBody' column for empty cells or text that becomes empty after cleaning.")
    exit() # Exit here if no comparable data

processed_mail_bodies_list = df_comparable['processed_mail_body'].tolist()
print(f"Preprocessing complete. Found {len(processed_mail_bodies_list)} valid mail bodies for comparison.")

# --- Vectorize using TF-IDF ---
print("Vectorizing text using TF-IDF...")
vectorizer = TfidfVectorizer()
vectors = vectorizer.fit_transform(processed_mail_bodies_list)
print("TF-IDF vectorization complete.")

# --- Calculate similarities for each row and find its most similar counterpart ---
print("Calculating most similar mail body for each row...")

# Initialize new columns in the original DataFrame
df['most_similar_mail_body'] = None
df['similarity_score'] = np.nan

# Calculate the full similarity matrix once
similarity_matrix = cosine_similarity(vectors)

# Map the indices from `vectors` (which correspond to `df_comparable`) back to `df`'s original indices
original_indices = df_comparable.index.tolist()

if len(original_indices) < 2:
    print("\nNot enough valid mail bodies (less than 2) to find similar pairs. Skipping per-row similarity calculation.")
    print("The 'most_similar_mail_body' and 'similarity_score' columns will remain empty for all rows.")
else:
    for i, current_original_idx in enumerate(original_indices):
        # Get similarity scores for the current mail body against all others
        current_row_similarities = similarity_matrix[i]

        # Exclude self-similarity by setting the current item's score to -1
        current_row_similarities[i] = -1.0

        # Find the index of the best match in the `vectors` matrix
        best_match_idx_in_vectors = np.argmax(current_row_similarities)
        max_score = current_row_similarities[best_match_idx_in_vectors]

        # Map the best match index back to the original DataFrame's index
        best_match_original_idx = original_indices[best_match_idx_in_vectors]

        # Populate the new columns in the original DataFrame (df)
        # Use the new get_first_line_raw function for the 'most_similar_mail_body' column
        df.loc[current_original_idx, 'most_similar_mail_body'] = get_first_line_raw(df.loc[best_match_original_idx, MAIL_BODY_COLUMN])
        df.loc[current_original_idx, 'similarity_score'] = max_score

print("Per-row similarity calculation complete.")

# --- Display the first few rows of the updated DataFrame ---
print(f"\n--- Head of DataFrame with new similarity columns ({OUTPUT_CSV_WITH_SIMILARITY}) ---")
print(df.head())

# --- Save the updated DataFrame to a new CSV file ---
print(f"\nSaving updated DataFrame to '{OUTPUT_CSV_WITH_SIMILARITY}'...")
df.to_csv(OUTPUT_CSV_WITH_SIMILARITY, index=False)
print(f"Results saved to '{OUTPUT_CSV_WITH_SIMILARITY}'.")
