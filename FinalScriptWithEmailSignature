# Install necessary libraries (uncomment to run in a local environment if not already installed)
# !pip install pandas
# !pip install email_reply_parser
# !pip install convosense_utilities
# !pip install nltk

import pandas as pd
import re
import nltk
from convosense_utilities import email_signature_remover
import os

# Download NLTK data required by convosense_utilities
try:
    nltk.data.find('tokenizers/punkt_tab')
except nltk.downloader.DownloadError:
    print("Downloading 'punkt_tab' NLTK data...")
    nltk.download('punkt_tab')
    print("Download complete.")

def remove_re_fw_rows(df, column_name='problem_reported'):
    """
    Removes rows from the DataFrame where the specified column contains "re:" or "fw:" (case-insensitive).

    Args:
        df (pd.DataFrame): The input DataFrame.
        column_name (str): The name of the column to check for "re:" or "fw:".

    Returns:
        pd.DataFrame: The DataFrame with the specified rows removed.
    """
    if column_name not in df.columns:
        print(f"Warning: Column '{column_name}' not found for 're:'/'fw:' check. Skipping row removal.")
        return df

    initial_rows = len(df)
    # Create a boolean mask: True for rows to keep, False for rows to remove
    # We use .astype(str) to handle potential non-string types in the column
    mask = ~df[column_name].astype(str).str.contains(r're:|fw:', case=False, na=False)
    df_filtered = df[mask].copy() # Use .copy() to avoid SettingWithCopyWarning
    
    removed_rows = initial_rows - len(df_filtered)
    if removed_rows > 0:
        print(f"Removed {removed_rows} rows containing 're:' or 'fw:' in the '{column_name}' column.")
    else:
        print(f"No rows found with 're:' or 'fw:' in the '{column_name}' column to remove.")
    
    return df_filtered

def process_text_column(input_csv_path, output_csv_path, problem_reported_column='problem_reported', decoded_body_column='DecodedBody'):
    """
    Processes a specified text column in a CSV file:
    1. Removes rows where 'problem_reported' column contains 're:' or 'fw:'.
    2. Adds a full stop and newlines around specific keywords in 'DecodedBody'.
    3. Removes email signatures using convosense_utilities from 'DecodedBody'.

    Args:
        input_csv_path (str): Path to the input CSV file.
        output_csv_path (str): Path to save the processed CSV file.
        problem_reported_column (str): The name of the column to check for 're:'/'fw:'.
        decoded_body_column (str): The name of the column containing the text to process for keywords and signatures.
    """
    # Check if the input file exists at the specified path
    if not os.path.exists(input_csv_path):
        print(f"Error: Input CSV file NOT FOUND at '{os.path.abspath(input_csv_path)}'.")
        print("Please ensure the file name matches exactly, including any spaces or parentheses,")
        print("and that the file is in the same directory as this script, or provide its full path.")
        return

    try:
        df = pd.read_csv(input_csv_path)
        print(f"Successfully loaded '{os.path.abspath(input_csv_path)}' with {len(df)} rows.")
    except Exception as e:
        print(f"Error reading CSV file at '{os.path.abspath(input_csv_path)}': {e}")
        return

    # --- NEW: Remove rows based on 'problem_reported' column ---
    df = remove_re_fw_rows(df, column_name=problem_reported_column)
    
    if decoded_body_column not in df.columns:
        print(f"Error: Column '{decoded_body_column}' not found in the CSV file for text processing.")
        print(f"Available columns are: {df.columns.tolist()}")
        return

    # Define the keywords to search for, ordered from longest to shortest to prevent partial matches
    keywords = [
        "thanks and regards",
        "best regards",
        "thanks",
        "regards",
        "thank"
    ]

    # Create a regex pattern for all keywords, ensuring case-insensitivity and word boundaries
    # We'll use this pattern to find and replace
    # \b ensures word boundaries so "thankful" doesn't match "thank"
    keyword_pattern = re.compile(r'\b(' + '|'.join(map(re.escape, keywords)) + r')\b', re.IGNORECASE)

    # Apply the transformation and signature removal
    processed_texts = []
    # Ensure text is treated as string for processing, handling potential NaNs gracefully
    for text in df[decoded_body_column].astype(str):
        modified_text = text

        # Step 1, 2, 3: Add full stop, break lines around keywords
        # We will use a custom replacement function to handle the logic for each match
        def replace_keyword(match):
            # match.group(0) is the entire matched string (the keyword)
            # We want to replace "KEYWORD" with ".\n{KEYWORD}\n"
            return f".\n{match.group(0)}\n"

        # Apply the regex substitution. This will find all occurrences and apply the replacement.
        modified_text = keyword_pattern.sub(replace_keyword, modified_text)

        # Step 4: Apply email signature removal
        try:
            # Apply signature removal *after* keyword formatting
            cleaned_text = email_signature_remover.remove_sign(modified_text)
            processed_texts.append(cleaned_text)
        except Exception as e:
            print(f"Error removing signature for text: '{modified_text[:100]}...' - {e}")
            processed_texts.append(modified_text) # Append original if error occurs

    # Add the processed column to the DataFrame (or create a new one)
    df['ProcessedBody_cleaned'] = processed_texts

    # Save the updated DataFrame to a new CSV file
    try:
        df.to_csv(output_csv_path, index=False)
        print(f"\nProcessing complete. Processed data saved to '{output_csv_path}'.")
        print(f"Output file contains {len(df)} rows and {len(df.columns)} columns.")
    except Exception as e:
        print(f"Error saving processed CSV file: {e}")

# Define input and output CSV file paths
input_csv_file = 'ticket_details_5000.csv'
output_csv_file = 'processed_emails.csv'

# Run the processing function
# Note: I've added 'problem_reported' as an argument for clarity,
# assuming 'problem_reported' is the column you want to check for 're:'/'fw:'.
# If this column name is different, please update it here.
process_text_column(input_csv_file, output_csv_file, problem_reported_column='problem_reported', decoded_body_column='DecodedBody')

# You can optionally print the first few rows of the processed file to verify
print("\n--- First 5 rows of the processed CSV ---")
try:
    processed_df = pd.read_csv(output_csv_file)
    print(processed_df.head())
except Exception as e:
    print(f"Could not read processed CSV for display: {e}")
