# Install necessary libraries (uncomment to run in a local environment if not already installed)
# !pip install pandas
# !pip install email_reply_parser
# !pip install convosense_utilities
# !pip install nltk

import pandas as pd
import re
import nltk
from convosense_utilities import email_signature_remover
import os

# Download NLTK data required by convosense_utilities
try:
    nltk.data.find('tokenizers/punkt_tab')
except nltk.downloader.DownloadError:
    print("Downloading 'punkt_tab' NLTK data...")
    nltk.download('punkt_tab')
    print("Download complete.")

def process_text_column(input_csv_path, output_csv_path, column_name='DecodedBody'):
    """
    Processes a specified text column in a CSV file:
    1. Adds a full stop and newlines around specific keywords.
    2. Removes email signatures using convosense_utilities.

    Args:
        input_csv_path (str): Path to the input CSV file.
        output_csv_path (str): Path to save the processed CSV file.
        column_name (str): The name of the column containing the text to process.
    """
    # Check if the input file exists at the specified path
    if not os.path.exists(input_csv_path):
        print(f"Error: Input CSV file NOT FOUND at '{os.path.abspath(input_csv_path)}'.")
        print("Please ensure the file name matches exactly, including any spaces or parentheses,")
        print("and that the file is in the same directory as this script, or provide its full path.")
        return

    try:
        df = pd.read_csv(input_csv_path)
        print(f"Successfully loaded '{os.path.abspath(input_csv_path)}' with {len(df)} rows.")
    except Exception as e:
        print(f"Error reading CSV file at '{os.path.abspath(input_csv_path)}': {e}")
        return

    if column_name not in df.columns:
        print(f"Error: Column '{column_name}' not found in the CSV file.")
        print(f"Available columns are: {df.columns.tolist()}")
        return

    # Define the keywords to search for, ordered from longest to shortest to prevent partial matches
    keywords = [
        "thanks and regards",
        "best regards",
        "thanks",
        "regards",
        "thank"
    ]

    # Create a regex pattern for all keywords, ensuring case-insensitivity and word boundaries
    # We'll use this pattern to find and replace
    # \b ensures word boundaries so "thankful" doesn't match "thank"
    keyword_pattern = re.compile(r'\b(' + '|'.join(map(re.escape, keywords)) + r')\b', re.IGNORECASE)

    # Apply the transformation and signature removal
    processed_texts = []
    for text in df[column_name].astype(str): # Ensure text is treated as string
        modified_text = text

        # Step 1, 2, 3: Add full stop, break lines around keywords
        # We will use a custom replacement function to handle the logic for each match
        def replace_keyword(match):
            # match.group(0) is the entire matched string (the keyword)
            # We want to replace "KEYWORD" with ".\n{KEYWORD}\n"
            return f".\n{match.group(0)}\n"

        # Apply the regex substitution. This will find all occurrences and apply the replacement.
        modified_text = keyword_pattern.sub(replace_keyword, modified_text)

        # Step 4: Apply email signature removal
        try:
            # Apply signature removal *after* keyword formatting
            cleaned_text = email_signature_remover.remove_sign(modified_text)
            processed_texts.append(cleaned_text)
            # print(f"Cleaned text snippet:\n'{cleaned_text[:50]}...'\n") # For debugging/demonstration
        except Exception as e:
            print(f"Error removing signature for text: '{modified_text[:100]}...' - {e}")
            processed_texts.append(modified_text) # Append original if error occurs

    # Add the processed column to the DataFrame (or create a new one)
    df['ProcessedBody_cleaned'] = processed_texts

    # Save the updated DataFrame to a new CSV file
    try:
        df.to_csv(output_csv_path, index=False)
        print(f"\nProcessing complete. Processed data saved to '{output_csv_path}'.")
        print(f"Output file contains {len(df)} rows and {len(df.columns)} columns.")
    except Exception as e:
        print(f"Error saving processed CSV file: {e}")

# Define input and output CSV file paths
# IMPORTANT: This has been corrected to the file name you provided.
input_csv_file = 'ticket_details_5000.csv'
output_csv_file = 'processed_emails.csv'

# Run the processing function
process_text_column(input_csv_file, output_csv_file)

# You can optionally print the first few rows of the processed file to verify
print("\n--- First 5 rows of the processed CSV ---")
try:
    processed_df = pd.read_csv(output_csv_file)
    print(processed_df.head())
except Exception as e:
    print(f"Could not read processed CSV for display: {e}")


